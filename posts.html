<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/44a48044965cc004.css" as="style"/><link rel="stylesheet" href="/_next/static/css/44a48044965cc004.css" data-n-g=""/><link rel="preload" href="/_next/static/css/f7248f181c2e6b29.css" as="style"/><link rel="stylesheet" href="/_next/static/css/f7248f181c2e6b29.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-fc7d2f0e2098927e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-98c6afcf3a360602.js" defer=""></script><script src="/_next/static/chunks/252f366e-32c0ef02bbec04ec.js" defer=""></script><script src="/_next/static/chunks/8b531612-536b98366e47f925.js" defer=""></script><script src="/_next/static/chunks/d64684d8-6f41d6cb185210ac.js" defer=""></script><script src="/_next/static/chunks/626-8f00c7eea2203cfc.js" defer=""></script><script src="/_next/static/chunks/119-1e8e9ac81652ac35.js" defer=""></script><script src="/_next/static/chunks/pages/posts-804d9ace81231a95.js" defer=""></script><script src="/_next/static/aitngYHlm5ehRrVt2fHoE/_buildManifest.js" defer=""></script><script src="/_next/static/aitngYHlm5ehRrVt2fHoE/_ssgManifest.js" defer=""></script><script src="/_next/static/aitngYHlm5ehRrVt2fHoE/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__CcNN1"><div class="Header_wrapper__YAiPg"><a class="Header_logo__M2Ygq" href="/">Lena Voita</a><nav class="Header_navigation__8nfJC"><ul><li><a class="Header_active__1TZtl" href="/posts">Blog</a></li><li><a class="" href="/papers">Publications</a></li><li><a class="" href="/talks">Talks &amp; Service</a></li><li><a class="" href="/nlp-course">NLP Course | For You</a></li></ul><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" class="Header_closeIcon___NJuS Header_menuIcon__Dr6iF" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></nav><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" class="Header_menuIcon__Dr6iF" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></div></header><div class="BaseTemplate_wrapper__JOBXv"><main class="BaseTemplate_main___I0ma"><div class="Card_root__O2p62" style="margin-bottom:20px"><article><h3 class="Preview_heading__m5V5x">NMT Training through the Lens of SMT</h3><span style="font-size:0.9em" class="Clarify_md__AlJNy"><p>This is a post for the EMNLP 2021 paper
<a href="https://arxiv.org/abs/2109.01396">Language Modeling, Lexical Translation, Reordering: The Training Process of NMT through the Lens of Classical SMT.</a></p></span>
<div class="Side_root__bSrHJ"><div class="Side_main__0xC89 Side_md__YoZwN"><p>In SMT, model competences are modelled with distinct models.
In NMT, the whole translation task is modelled
with a single neural network.
How and when does NMT get to learn all the competences? We show that</p><ul>
<li>during training, NMT undergoes three different stages:</li>
<li>target-side language modeling,</li>
<li>learning how to use source and approaching word-by-word translation,</li>
<li>refining translations, visible by increasingly complex reorderings,
but almost invisible to standard metrics (e.g. BLEU);</li>
</ul></div><div class="Side_side__j9ioX"><p><img src="/posts/nmt-training-through-smt-lens/morda-min.webp" alt="morda-min" class="Image_image__k5v2O"/></p></div></div>
<ul>
<li>not only this is fun, but it can also help in practice! For example, in settings where
data complexity matters, such as non-autoregressive NMT.</li>
</ul><div class="Preview_bottom__8CJtQ"><div class="Preview_buttons__ha5nu"><a class="Button_button__u6V9N" href="posts/nmt-training-through-smt-lens"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M8.59 16.59L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.41z"></path></svg>read more</a><a class="Button_button__u6V9N" href="https://arxiv.org/abs/2109.01396"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0z"></path><path d="M20.41 8.41l-4.83-4.83c-.37-.37-.88-.58-1.41-.58H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V9.83c0-.53-.21-1.04-.59-1.42zM7 7h7v2H7V7zm10 10H7v-2h10v2zm0-4H7v-2h10v2z"></path></svg>read paper</a></div><span class="Preview_year__xD86I">September 2021</span></div></article></div><div class="Card_root__O2p62" style="margin-bottom:20px"><article><h3 class="Preview_heading__m5V5x">Neural Machine Translation Inside Out</h3><div class="Side_root__bSrHJ"><div class="Side_main__0xC89 Side_md__YoZwN"><span style="font-size:0.9em" class="Clarify_sx__WKZPq"><p>This is a blog version of my talk at the ACL 2021 workshop
<a href="https://sites.google.com/view/repl4nlp-2021/">Representation Learning for NLP</a> (and updated version
of that at NAACL 2021 workshop <a href="https://sites.google.com/view/deelio-ws/">Deep Learning Inside Out (DeeLIO)</a> ).</p></span><p>In the last decade, machine translation shifted from the traditional statistical approaches
with distinct components and hand-crafted features to the end-to-end neural ones.
We try to understand how NMT works and show that:</p><ul>
<li>NMT model components can learn to extract features which in SMT were modelled explicitly;</li>
<li>for NMT, we can also look at how it balances the two different types of context: the source and the prefix;</li>
<li>NMT training consists of the stages where it focuses on competences mirroring three core SMT components.</li>
</ul></div><div class="Side_side__j9ioX"><p><img src="/posts/nmt-inside-out/morda_test.webp" alt="" class="Image_image__k5v2O"/></p></div></div><div class="Preview_bottom__8CJtQ"><div class="Preview_buttons__ha5nu"><a class="Button_button__u6V9N" href="posts/nmt-inside-out"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M8.59 16.59L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.41z"></path></svg>read more</a></div><span class="Preview_year__xD86I">July 2021</span></div></article></div><div class="Card_root__O2p62" style="margin-bottom:20px"><article><h3 class="Preview_heading__m5V5x">Source and Target Contributions to NMT Predictions</h3><span style="font-size:0.9em" class="Clarify_sx__WKZPq"><p>This is a post for the ACL 2021 paper
<a href="https://arxiv.org/pdf/2010.10907.pdf">Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation.</a></p></span>
<div class="Side_root__bSrHJ"><div class="Side_main__0xC89"><p>In NMT, each prediction is based on two types of context: the source and the prefix of the target sentence.
We show how to evaluate the relative contributions of source and target to NMT predictions and find that:</p><ul>
<li>models suffering from exposure bias are more prone to over-relying on target history (and hence to hallucinating) than
the ones where the exposure bias is mitigated;</li>
<li>models trained with more data rely on the source more and do it more confidently;</li>
<li>the training process is non-monotonic with several distinct stages.</li>
</ul></div><div class="Side_side__j9ioX"><video width="100%" height="auto" loop="" autoplay="" muted=""><source src="/posts/src-dst-nmt/src_dst_main.mp4" type="video/mp4"/></video></div></div><div class="Preview_bottom__8CJtQ"><div class="Preview_buttons__ha5nu"><a class="Button_button__u6V9N" href="posts/source-target-contributions-to-nmt"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 24 24" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill="none" d="M0 0h24v24H0V0z"></path><path d="M8.59 16.59L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.41z"></path></svg>read more</a></div><span class="Preview_year__xD86I">July 2021</span></div></article></div></main></div><footer class="Footer_root__OEatj"><div class="Footer_wrapper___n7Sm"><div class="Footer_icons__uI7wp"><a href="https://msclogic.illc.uva.nl/people/students/">pic</a><a href="mailto:lena-voita@hotmail.com">pic</a><a href="https://scholar.google.com/citations?user=EcN9o7kAAAAJ">pic</a><a href="https://github.com/lena-voita">pic</a><a href="https://twitter.com/lena_voita">pic</a></div><p>Last updated by </p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"pages":[{"slug":"posts/nmt-training-through-smt-lens","meta":{"layout":"post","title":"NMT Training through the Lens of SMT","image":"/posts/nmt-training-through-smt-lens/morda-min.webp","menu":true,"order":0,"date":"2021-09-01T00:00:00.000Z","paper":"https://arxiv.org/abs/2109.01396"},"preview":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      p: \"p\",\n      a: \"a\",\n      ul: \"ul\",\n      li: \"li\",\n      img: \"img\"\n    }, _provideComponents(), props.components), {Cl, SideContainer, Main, Side} = _components;\n    if (!Cl) _missingMdxReference(\"Cl\", true);\n    if (!Main) _missingMdxReference(\"Main\", true);\n    if (!Side) _missingMdxReference(\"Side\", true);\n    if (!SideContainer) _missingMdxReference(\"SideContainer\", true);\n    return _jsxs(_Fragment, {\n      children: [_jsx(Cl, {\n        size: \"md\",\n        children: _jsxs(_components.p, {\n          children: [\"This is a post for the EMNLP 2021 paper\\n\", _jsx(_components.a, {\n            href: \"https://arxiv.org/abs/2109.01396\",\n            children: \"Language Modeling, Lexical Translation, Reordering: The Training Process of NMT through the Lens of Classical SMT.\"\n          })]\n        })\n      }), \"\\n\", _jsxs(SideContainer, {\n        children: [_jsxs(Main, {\n          md: true,\n          children: [_jsx(_components.p, {\n            children: \"In SMT, model competences are modelled with distinct models.\\nIn NMT, the whole translation task is modelled\\nwith a single neural network.\\nHow and when does NMT get to learn all the competences? We show that\"\n          }), _jsxs(_components.ul, {\n            children: [\"\\n\", _jsx(_components.li, {\n              children: \"during training, NMT undergoes three different stages:\"\n            }), \"\\n\", _jsx(_components.li, {\n              children: \"target-side language modeling,\"\n            }), \"\\n\", _jsx(_components.li, {\n              children: \"learning how to use source and approaching word-by-word translation,\"\n            }), \"\\n\", _jsx(_components.li, {\n              children: \"refining translations, visible by increasingly complex reorderings,\\nbut almost invisible to standard metrics (e.g. BLEU);\"\n            }), \"\\n\"]\n          })]\n        }), _jsx(Side, {\n          children: _jsx(_components.p, {\n            children: _jsx(_components.img, {\n              src: \"/posts/nmt-training-through-smt-lens/morda-min.webp\",\n              alt: \"morda-min\"\n            })\n          })\n        })]\n      }), \"\\n\", _jsxs(_components.ul, {\n        children: [\"\\n\", _jsx(_components.li, {\n          children: \"not only this is fun, but it can also help in practice! For example, in settings where\\ndata complexity matters, such as non-autoregressive NMT.\"\n        }), \"\\n\"]\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},{"slug":"posts/nmt-inside-out","meta":{"layout":"post","title":"Neural Machine Translation Inside Out","description":"Lena Voita's keynote at ACL 2021 workshop RepL4NLP and NAACL 2021 workshop DeeLIO.","image":"/posts/nmt-inside-out/morda_test.webp","menu":true,"order":1,"date":"2021-07-01T00:00:00.000Z"},"preview":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      p: \"p\",\n      a: \"a\",\n      ul: \"ul\",\n      li: \"li\",\n      img: \"img\"\n    }, _provideComponents(), props.components), {SideContainer, Main, Cl, Side} = _components;\n    if (!Cl) _missingMdxReference(\"Cl\", true);\n    if (!Main) _missingMdxReference(\"Main\", true);\n    if (!Side) _missingMdxReference(\"Side\", true);\n    if (!SideContainer) _missingMdxReference(\"SideContainer\", true);\n    return _jsxs(SideContainer, {\n      children: [_jsxs(Main, {\n        md: true,\n        children: [_jsx(Cl, {\n          children: _jsxs(_components.p, {\n            children: [\"This is a blog version of my talk at the ACL 2021 workshop\\n\", _jsx(_components.a, {\n              href: \"https://sites.google.com/view/repl4nlp-2021/\",\n              children: \"Representation Learning for NLP\"\n            }), \" (and updated version\\nof that at NAACL 2021 workshop \", _jsx(_components.a, {\n              href: \"https://sites.google.com/view/deelio-ws/\",\n              children: \"Deep Learning Inside Out (DeeLIO)\"\n            }), \" ).\"]\n          })\n        }), _jsx(_components.p, {\n          children: \"In the last decade, machine translation shifted from the traditional statistical approaches\\nwith distinct components and hand-crafted features to the end-to-end neural ones.\\nWe try to understand how NMT works and show that:\"\n        }), _jsxs(_components.ul, {\n          children: [\"\\n\", _jsx(_components.li, {\n            children: \"NMT model components can learn to extract features which in SMT were modelled explicitly;\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"for NMT, we can also look at how it balances the two different types of context: the source and the prefix;\"\n          }), \"\\n\", _jsx(_components.li, {\n            children: \"NMT training consists of the stages where it focuses on competences mirroring three core SMT components.\"\n          }), \"\\n\"]\n        })]\n      }), _jsx(Side, {\n        children: _jsx(_components.p, {\n          children: _jsx(_components.img, {\n            src: \"/posts/nmt-inside-out/morda_test.webp\",\n            alt: \"\"\n          })\n        })\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},{"slug":"posts/source-target-contributions-to-nmt","meta":{"layout":"post","title":"Source and Target Contributions to NMT Predictions","description":"Lena Voita's keynote at ACL 2021 workshop RepL4NLP and NAACL 2021 workshop DeeLIO.","image":"/posts/nmt-inside-out/morda_test.webp","menu":true,"order":2,"date":"2021-07-01T00:00:00.000Z"},"preview":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      p: \"p\",\n      a: \"a\",\n      ul: \"ul\",\n      li: \"li\"\n    }, _provideComponents(), props.components), {Cl, SideContainer, Main, Side} = _components;\n    if (!Cl) _missingMdxReference(\"Cl\", true);\n    if (!Main) _missingMdxReference(\"Main\", true);\n    if (!Side) _missingMdxReference(\"Side\", true);\n    if (!SideContainer) _missingMdxReference(\"SideContainer\", true);\n    return _jsxs(_Fragment, {\n      children: [_jsx(Cl, {\n        children: _jsxs(_components.p, {\n          children: [\"This is a post for the ACL 2021 paper\\n\", _jsx(_components.a, {\n            href: \"https://arxiv.org/pdf/2010.10907.pdf\",\n            children: \"Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation.\"\n          })]\n        })\n      }), \"\\n\", _jsxs(SideContainer, {\n        children: [_jsxs(Main, {\n          children: [_jsx(_components.p, {\n            children: \"In NMT, each prediction is based on two types of context: the source and the prefix of the target sentence.\\nWe show how to evaluate the relative contributions of source and target to NMT predictions and find that:\"\n          }), _jsxs(_components.ul, {\n            children: [\"\\n\", _jsx(_components.li, {\n              children: \"models suffering from exposure bias are more prone to over-relying on target history (and hence to hallucinating) than\\nthe ones where the exposure bias is mitigated;\"\n            }), \"\\n\", _jsx(_components.li, {\n              children: \"models trained with more data rely on the source more and do it more confidently;\"\n            }), \"\\n\", _jsx(_components.li, {\n              children: \"the training process is non-monotonic with several distinct stages.\"\n            }), \"\\n\"]\n          })]\n        }), _jsx(Side, {\n          children: _jsx(\"video\", {\n            width: \"100%\",\n            height: \"auto\",\n            loop: true,\n            autoPlay: true,\n            muted: true,\n            children: _jsx(\"source\", {\n              src: \"/posts/src-dst-nmt/src_dst_main.mp4\",\n              type: \"video/mp4\"\n            })\n          })\n        })]\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}}]},"__N_SSG":true},"page":"/posts","query":{},"buildId":"aitngYHlm5ehRrVt2fHoE","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>