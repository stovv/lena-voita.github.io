<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/44a48044965cc004.css" as="style"/><link rel="stylesheet" href="/_next/static/css/44a48044965cc004.css" data-n-g=""/><link rel="preload" href="/_next/static/css/8764ea50cea876ea.css" as="style"/><link rel="stylesheet" href="/_next/static/css/8764ea50cea876ea.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/_next/static/chunks/webpack-9b312e20a4e32339.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-fc7d2f0e2098927e.js" defer=""></script><script src="/_next/static/chunks/pages/_app-98c6afcf3a360602.js" defer=""></script><script src="/_next/static/chunks/252f366e-32c0ef02bbec04ec.js" defer=""></script><script src="/_next/static/chunks/8b531612-536b98366e47f925.js" defer=""></script><script src="/_next/static/chunks/d64684d8-6f41d6cb185210ac.js" defer=""></script><script src="/_next/static/chunks/626-8f00c7eea2203cfc.js" defer=""></script><script src="/_next/static/chunks/547-9b2136a49167c5ee.js" defer=""></script><script src="/_next/static/chunks/119-1e8e9ac81652ac35.js" defer=""></script><script src="/_next/static/chunks/pages/%5B...slug%5D-64b1235861c92fc3.js" defer=""></script><script src="/_next/static/aitngYHlm5ehRrVt2fHoE/_buildManifest.js" defer=""></script><script src="/_next/static/aitngYHlm5ehRrVt2fHoE/_ssgManifest.js" defer=""></script><script src="/_next/static/aitngYHlm5ehRrVt2fHoE/_middlewareManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__CcNN1"><div class="Header_wrapper__YAiPg"><a class="Header_logo__M2Ygq" href="/">Lena Voita</a><nav class="Header_navigation__8nfJC"><ul><li><a class="" href="/posts">Blog</a></li><li><a class="" href="/papers">Publications</a></li><li><a class="" href="/talks">Talks &amp; Service</a></li><li><a class="" href="/nlp-course">NLP Course | For You</a></li></ul><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" class="Header_closeIcon___NJuS Header_menuIcon__Dr6iF" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></nav><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 20 20" class="Header_menuIcon__Dr6iF" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></div></header><div class="BaseTemplate_wrapper__JOBXv"><main class="BaseTemplate_main___I0ma"><h1>Neural Machine Translation Inside Out</h1><article><h3 class="Preview_heading__m5V5x"></h3><div class="Side_root__bSrHJ"><div class="Side_main__0xC89 Side_md__YoZwN"><span style="font-size:0.9em" class="Clarify_sx__WKZPq"><p>This is a blog version of my talk at the ACL 2021 workshop
<a href="https://sites.google.com/view/repl4nlp-2021/">Representation Learning for NLP</a> (and updated version
of that at NAACL 2021 workshop <a href="https://sites.google.com/view/deelio-ws/">Deep Learning Inside Out (DeeLIO)</a> ).</p></span><p>In the last decade, machine translation shifted from the traditional statistical approaches
with distinct components and hand-crafted features to the end-to-end neural ones.
We try to understand how NMT works and show that:</p><ul>
<li>NMT model components can learn to extract features which in SMT were modelled explicitly;</li>
<li>for NMT, we can also look at how it balances the two different types of context: the source and the prefix;</li>
<li>NMT training consists of the stages where it focuses on competences mirroring three core SMT components.</li>
</ul></div><div class="Side_side__j9ioX"><p><img src="/posts/nmt-inside-out/morda_test.webp" alt="" class="Image_image__k5v2O"/></p></div></div><div class="Preview_bottom__8CJtQ"><div class="Preview_buttons__ha5nu"></div></div></article>
<hr/>
<h2 id="test">Test</h2></main></div><footer class="Footer_root__OEatj"><div class="Footer_wrapper___n7Sm"><div class="Footer_icons__uI7wp"><a href="https://msclogic.illc.uva.nl/people/students/">pic</a><a href="mailto:lena-voita@hotmail.com">pic</a><a href="https://scholar.google.com/citations?user=EcN9o7kAAAAJ">pic</a><a href="https://github.com/lena-voita">pic</a><a href="https://twitter.com/lena_voita">pic</a></div><p>Last updated by </p></div></footer></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"meta":{"layout":"post","title":"Neural Machine Translation Inside Out","description":"Lena Voita's keynote at ACL 2021 workshop RepL4NLP and NAACL 2021 workshop DeeLIO.","image":"/posts/nmt-inside-out/morda_test.webp","menu":true,"order":1,"date":"2021-07-01T00:00:00.000Z","contentTable":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    return _jsx(_Fragment, {});\n  }\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"slug":["posts","nmt-inside-out"],"mdxSource":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, {})\n  })) : _createMdxContent();\n  function _createMdxContent() {\n    const _components = Object.assign({\n      p: \"p\",\n      a: \"a\",\n      ul: \"ul\",\n      li: \"li\",\n      img: \"img\",\n      hr: \"hr\",\n      h1: \"h1\"\n    }, _provideComponents(), props.components), {Preview, SideContainer, Main, Cl, Side} = _components;\n    if (!Cl) _missingMdxReference(\"Cl\", true);\n    if (!Main) _missingMdxReference(\"Main\", true);\n    if (!Preview) _missingMdxReference(\"Preview\", true);\n    if (!Side) _missingMdxReference(\"Side\", true);\n    if (!SideContainer) _missingMdxReference(\"SideContainer\", true);\n    return _jsxs(_Fragment, {\n      children: [_jsx(Preview, {\n        children: _jsxs(SideContainer, {\n          children: [_jsxs(Main, {\n            md: true,\n            children: [_jsx(Cl, {\n              children: _jsxs(_components.p, {\n                children: [\"This is a blog version of my talk at the ACL 2021 workshop\\n\", _jsx(_components.a, {\n                  href: \"https://sites.google.com/view/repl4nlp-2021/\",\n                  children: \"Representation Learning for NLP\"\n                }), \" (and updated version\\nof that at NAACL 2021 workshop \", _jsx(_components.a, {\n                  href: \"https://sites.google.com/view/deelio-ws/\",\n                  children: \"Deep Learning Inside Out (DeeLIO)\"\n                }), \" ).\"]\n              })\n            }), _jsx(_components.p, {\n              children: \"In the last decade, machine translation shifted from the traditional statistical approaches\\nwith distinct components and hand-crafted features to the end-to-end neural ones.\\nWe try to understand how NMT works and show that:\"\n            }), _jsxs(_components.ul, {\n              children: [\"\\n\", _jsx(_components.li, {\n                children: \"NMT model components can learn to extract features which in SMT were modelled explicitly;\"\n              }), \"\\n\", _jsx(_components.li, {\n                children: \"for NMT, we can also look at how it balances the two different types of context: the source and the prefix;\"\n              }), \"\\n\", _jsx(_components.li, {\n                children: \"NMT training consists of the stages where it focuses on competences mirroring three core SMT components.\"\n              }), \"\\n\"]\n            })]\n          }), _jsx(Side, {\n            children: _jsx(_components.p, {\n              children: _jsx(_components.img, {\n                src: \"/posts/nmt-inside-out/morda_test.webp\",\n                alt: \"\"\n              })\n            })\n          })]\n        })\n      }), \"\\n\", _jsx(_components.hr, {}), \"\\n\", _jsx(_components.h1, {\n        children: \"Test\"\n      })]\n    });\n  }\n}\nreturn {\n  default: MDXContent\n};\nfunction _missingMdxReference(id, component) {\n  throw new Error(\"Expected \" + (component ? \"component\" : \"object\") + \" `\" + id + \"` to be defined: you likely forgot to import, pass, or provide it.\");\n}\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/[...slug]","query":{"slug":["posts","nmt-inside-out"]},"buildId":"aitngYHlm5ehRrVt2fHoE","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>